{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0699278c-2daa-47e5-9f5f-bba30bcc448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src') \n",
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Project modules\n",
    "from data_preprocessing import load_and_preprocess_data, random_forest_feature_selection, create_specific_dataframe\n",
    "from model import create_binary_classifier, train_other_classes, ClassFinalClassifier\n",
    "from model_utils import generate_report, save_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030e09b3-8135-46cd-a581-5203246673af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_function(target_class, n_features_to_select, sampling_method, model_type, output_dir):\n",
    "    \"\"\"\n",
    "    Main function that performs data loading, preprocessing, model training, evaluation, and reporting.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # 1. Data loading and preprocessing\n",
    "    train_data_raw, X, y, X_train, X_test, y_train, y_test = load_and_preprocess_data('../data/raw/train.csv', target_class, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 2. Feature selection\n",
    "    selected_features, X_selected = random_forest_feature_selection(X, y, n_features_to_select)\n",
    "\n",
    "    # 3. Creating target class numeric data\n",
    "    y_train_target = create_specific_dataframe(train_data_raw, target_class, target_column='target')\n",
    "\n",
    "    # 4. Create the classifier\n",
    "    classifier = create_binary_classifier(X_selected, y_train_target, 1, sampling_method=sampling_method)\n",
    "    classifier_others = train_other_classes(X_selected, y_train_target, class_value=1, model_type=model_type)\n",
    "\n",
    "    # 5. Model ensemble\n",
    "    class_final_clf_model = ClassFinalClassifier(classifier, classifier_others)\n",
    "    class_final_clf_model.fit(X_selected, y_train_target)\n",
    "\n",
    "    # 6. Get predictions from each model and save\n",
    "    predictions_class1 = classifier.predict(X_test[selected_features])\n",
    "    predictions_others = classifier_others.predict(X_test[selected_features])\n",
    "    final_predictions = class_final_clf_model.predict(X_test[selected_features])\n",
    "\n",
    "    # Convert predictions to a DataFrame\n",
    "    predictions_df = pd.DataFrame({\n",
    "        \"Actual\": y_test,\n",
    "        \"Predictions_Class1\": predictions_class1,\n",
    "        \"Predictions_Others\": predictions_others,\n",
    "        \"Final_Predictions\": final_predictions\n",
    "    })\n",
    "\n",
    "    # 7. Evaluate the model and generate report\n",
    "    # Passing the model name (e.g., target_class) to generate the report\n",
    "    generate_report(y_test, final_predictions, model_name=target_class)\n",
    "\n",
    "    # 8. Check for overfitting\n",
    "    train_accuracy = class_final_clf_model.score(X_train[selected_features], y_train)\n",
    "    test_accuracy = class_final_clf_model.score(X_test[selected_features], y_test)\n",
    "    print(\"Training Accuracy:\", train_accuracy)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # 9. Cross-validation\n",
    "    cv_scores = cross_val_score(class_final_clf_model, X_train[selected_features], y_train, cv=5, scoring='accuracy')\n",
    "    print(\"Cross-Validation Scores:\", cv_scores)\n",
    "    print(\"Average CV Score:\", cv_scores.mean())\n",
    "\n",
    "    # 10. Save the reports\n",
    "    generate_report(y_test, final_predictions, model_name=target_class, output_dir=output_dir)\n",
    "\n",
    "    return class_final_clf_model, selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4003d9dc-d9a9-4de6-82ae-895f89a334a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_strategies = {\n",
    "    'Class_1': {'n_features_to_select': 15, 'sampling_method': 'smote', 'model_type': 'random_forest'},\n",
    "    'Class_2': {'n_features_to_select': 15, 'sampling_method': 'under_sampling', 'model_type': 'random_forest'},\n",
    "    'Class_3': {'n_features_to_select': 12, 'sampling_method': 'none', 'model_type': 'random_forest'},\n",
    "    'Class_4': {'n_features_to_select': 12, 'sampling_method': 'smote', 'model_type': 'xgboost'},\n",
    "    'Class_5': {'n_features_to_select': 11, 'sampling_method': 'smote', 'model_type': 'xgboost'},\n",
    "    'Class_6': {'n_features_to_select': 13, 'sampling_method': 'smote', 'model_type': 'xgboost'},\n",
    "    'Class_7': {'n_features_to_select': 10, 'sampling_method': 'random', 'model_type': 'random_forest'},\n",
    "    'Class_8': {'n_features_to_select': 12, 'sampling_method': 'none', 'model_type': 'random_forest'},\n",
    "    'Class_9': {'n_features_to_select': 15, 'sampling_method': 'under_sampling', 'model_type': 'xgboost'}\n",
    "}\n",
    "\n",
    "# Create directories if they don't exist\n",
    "models_dir = '../models'\n",
    "predictions_dir = '../predictions'\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "if not os.path.exists(predictions_dir):\n",
    "    os.makedirs(predictions_dir)\n",
    "\n",
    "# Loop to run main_function for each target class\n",
    "predictions_dict = {}  # Dictionary to store predictions\n",
    "\n",
    "for target_class, strategy in class_strategies.items():\n",
    "    print(f\"Running main_function for {target_class}...\")\n",
    "    \n",
    "    # Train the model\n",
    "    model, selected_features = main_function(\n",
    "        target_class=target_class,\n",
    "        n_features_to_select=strategy['n_features_to_select'],\n",
    "        sampling_method=strategy['sampling_method'],\n",
    "        model_type=strategy['model_type'],\n",
    "        output_dir=predictions_dir\n",
    "    )\n",
    "    \n",
    "    model_filename = f\"{target_class}_{strategy['model_type']}_model.pkl\"\n",
    "    model_filepath = os.path.join(models_dir, model_filename)\n",
    "    joblib.dump(model, model_filepath)\n",
    "    print(f\"Model for {target_class} has been trained and saved as {model_filepath}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5be369-ecc3-4f60-b9f1-0947c26815e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. Load models (previously saved models)\n",
    "model_paths = [\n",
    "    '../models/Class_1_random_forest_model.pkl', \n",
    "    '../models/Class_2_random_forest_model.pkl', \n",
    "    '../models/Class_3_random_forest_model.pkl', \n",
    "    '../models/Class_4_xgboost_model.pkl', \n",
    "    '../models/Class_5_xgboost_model.pkl', \n",
    "    '../models/Class_6_xgboost_model.pkl', \n",
    "    '../models/Class_7_random_forest_model.pkl', \n",
    "    '../models/Class_8_random_forest_model.pkl', \n",
    "    '../models/Class_9_xgboost_model.pkl'\n",
    "]\n",
    "\n",
    "# Load models\n",
    "models = [joblib.load(path) for path in model_paths]\n",
    "\n",
    "# 2. Load training and test datasets\n",
    "train_df = pd.read_csv('../data/raw/train.csv')\n",
    "test_df = pd.read_csv('../data/raw/test.csv')\n",
    "\n",
    "# Separate features and target variable\n",
    "X_train = train_df.drop(columns=['id', 'target'])\n",
    "y_train = train_df['target']\n",
    "X_test = test_df.drop(columns=['id'])\n",
    "\n",
    "# 3. Define the Voting Classifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('rf1', models[0]), ('rf2', models[1]), ('rf3', models[2]), \n",
    "                ('xgb1', models[3]), ('xgb2', models[4]), ('xgb3', models[5]), \n",
    "                ('rf4', models[6]), ('rf5', models[7]), ('xgb4', models[8])],\n",
    "    voting='soft'  # 'soft' uses probabilities\n",
    ")\n",
    "\n",
    "# 4. Train the voting classifier\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# 5. Make probability predictions on the test set\n",
    "y_pred_proba = voting_clf.predict_proba(X_test)\n",
    "\n",
    "# 6. Save results in sampleSubmission.csv format\n",
    "sample_submission = pd.read_csv('../data/raw/sampleSubmission.csv')\n",
    "\n",
    "# Create columns for each class\n",
    "classes = sample_submission.columns[1:]  # First column is 'id', class names follow\n",
    "submission_result = sample_submission.copy()\n",
    "\n",
    "# Place the results correctly\n",
    "for i, class_name in enumerate(classes):\n",
    "    submission_result[class_name] = y_pred_proba[:, i]\n",
    "\n",
    "# Save the results to ../submission folder\n",
    "submission_path = '../submission/voting_classifier_probabilities.csv'\n",
    "submission_result.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"Voting Classifier Predictions with probabilities saved successfully to {submission_path}!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
